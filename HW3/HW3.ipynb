{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import gc\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "prop_data = pd.read_csv(\"./data/properties_2017.csv\")\n",
    "# prop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/train_2017.csv\", parse_dates=[\"transactiondate\"])\n",
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original = prop_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_data = original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_data.loc[(prop_data[\"heatingorsystemtypeid\"]==2.0) & (pd.isnull(prop_data[\"airconditioningtypeid\"])), \"airconditioningtypeid\"] = 1.0\n",
    "\n",
    "prop_data[\"airconditioningtypeid\"].fillna(0, inplace=True)\n",
    "prop_data[\"airconditioningtypeid\"] = prop_data[\"airconditioningtypeid\"].map({1:1,13:1,5:0,9:1,11:1,12:1,3:1})\n",
    "\n",
    "prop_data['actual_area'] = prop_data['calculatedfinishedsquarefeet']\n",
    "prop_data['calculatedbathnbr'].fillna(prop_data['calculatedbathnbr'].median(),inplace = True)\n",
    "prop_data['bedroomcnt'].fillna(prop_data['bedroomcnt'].median(), inplace = True)\n",
    "\n",
    "prop_data['taxvaluedollarcnt'].fillna(prop_data[\"taxvaluedollarcnt\"].mean(), inplace=True)\n",
    "\n",
    "prop_data['actual_area'].replace(to_replace=1.0,value=np.nan,inplace=True)\n",
    "prop_data['actual_area'].fillna(prop_data['actual_area'].median(),inplace=True)\n",
    "\n",
    "prop_data['unitcnt'].fillna(1, inplace = True)\n",
    "\n",
    "prop_data['latitude'].fillna(prop_data['latitude'].median(),inplace = True)\n",
    "prop_data['longitude'].fillna(prop_data['longitude'].median(),inplace = True)\n",
    "\n",
    "prop_data['lotsizesquarefeet'].fillna(prop_data['lotsizesquarefeet'].median(), inplace = True)\n",
    "\n",
    "prop_data[\"poolcnt\"].fillna(0, inplace=True)\n",
    "prop_data[\"fireplacecnt\"].fillna(0, inplace=True)\n",
    "prop_data[\"hashottuborspa\"].fillna(0, inplace=True)\n",
    "prop_data['hashottuborspa'] = pd.to_numeric(prop_data['hashottuborspa'])\n",
    "\n",
    "prop_data[\"taxdelinquencyflag\"].fillna(-1, inplace=True)\n",
    "prop_data[\"taxdelinquencyflag\"] = prop_data[\"taxdelinquencyflag\"].map({'Y':1, -1:-1})\n",
    "\n",
    "prop_data.loc[(prop_data[\"heatingorsystemtypeid\"]==2.0) & (pd.isnull(prop_data[\"airconditioningtypeid\"])), \"airconditioningtypeid\"] = 1.0\n",
    "prop_data[\"airconditioningtypeid\"].fillna(-1, inplace=True)\n",
    "\n",
    "prop_data[\"buildingqualitytypeid\"].fillna(7, inplace=True)\n",
    "\n",
    "prop_data[\"yearbuilt\"].fillna(prop_data[\"yearbuilt\"].mean(), inplace=True)\n",
    "prop_data[\"age\"] = 2017 - prop_data[\"yearbuilt\"]\n",
    "\n",
    "#imputing garagecarcnt on basis of propertylandusetypeid\n",
    "\n",
    "#All the residential places have 1 or 2 garagecarcnt, hence using random filling for those values.\n",
    "\n",
    "prop_data.loc[(prop_data[\"propertylandusetypeid\"]==261) & (pd.isnull(prop_data[\"garagecarcnt\"])), \"garagecarcnt\"] = np.random.randint(1,3)\n",
    "prop_data.loc[(prop_data[\"propertylandusetypeid\"]==266) & (pd.isnull(prop_data[\"garagecarcnt\"])), \"garagecarcnt\"] = np.random.randint(1,3)\n",
    "prop_data[\"garagecarcnt\"].fillna(0, inplace=True)\n",
    "\n",
    "prop_data[\"taxamount\"].fillna(prop_data.taxamount.mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "colsList = [\"actual_area\",\n",
    "            \"poolcnt\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"unitcnt\",\n",
    "            \"lotsizesquarefeet\",\n",
    "            \"bedroomcnt\",\n",
    "            \"calculatedbathnbr\",\n",
    "            \"hashottuborspa\",\n",
    "            \"fireplacecnt\",\n",
    "            \"taxvaluedollarcnt\",\n",
    "            \"buildingqualitytypeid\",\n",
    "            \"garagecarcnt\",\n",
    "            \"age\",\n",
    "            \"taxamount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prop_data_ahp = prop_data[colsList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for col in prop_data_ahp.columns:\n",
    "    prop_data_ahp[col] = (prop_data_ahp[col] - prop_data_ahp[col].mean())/prop_data_ahp[col].std(ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Hierarchical Processing\n",
    "\n",
    "In this question, we used Analytic Hierarchy Process (AHP) to compute a score of the desirability of the parcels. In AHP the problem is broken into a hierarchy of easy-to-comprehend sub-problems. In this model we used the following metrics:\n",
    "1. Actual Area: Total area of the house including the area of the floors\n",
    "2. Pool Count: Number of pools in the house\n",
    "3. Latitude & Longitude: Coordinates of the house\n",
    "4. Unit Count: Number of units in the house\n",
    "5. Lot Size: Area of the land\n",
    "6. Bedroom and Bathroom count: Number of bathrooms and bedrooms\n",
    "7. Hot Tub or Spa Present: If a hot tub or spa is present or not\n",
    "8. Fireplace present: If a fireplace is present\n",
    "9. Tax Value: The total tax value of the parcel\n",
    "10. Building Type\n",
    "11. Garage count: Number of cars that can fit in the garage\n",
    "12. Age: Age of the parcel\n",
    "13. Tax Amount: Total property tax assessed for that year\n",
    "14. Air Conditioning Type: If the parcel is air conditioned or not\n",
    "15. Region Id County: County of the parcel\n",
    "\n",
    "In AHP, we give a relative importance to each of the above mentioned parameters as compared to the other parameters. Once the hierarchy is built, we evaluate its elements by comparing them to each other two elements at a time. For example, consider the example of Actual Area vs Pool Count. We think that Actual Area is 7 times more important than the pool count i.e. according to us having a bigger actual area of the property is more important than having a pool in the property. \n",
    "The full list of comparisons is available in the distance_metric.csv file committed to the repository. After this table is ready with policy scores and attribute weights, we can apply Simple Additive Weighting (SAW) and Weighted Product Model (WPM) to get to a decision.\n",
    "\n",
    "### Simple Additive Weighting (SAW)\n",
    "In general, suppose that a given MCDA problem is defined on m alternatives and n decision criteria. Furthermore, let us assume that all the criteria are benefit criteria, that is, the higher the values are, the better it is. Next suppose that wj denotes the relative weight of importance of the criterion Cj and aij is the performance value of alternative Ai when it is evaluated in terms of criterion Cj. Then, the total (i.e., when all the criteria are considered simultaneously) importance of alternative Ai, denoted as AiWSM-score, is defined as follows:\n",
    "\n",
    "SAW decision values:\n",
    "P1 = 6.019\n",
    "P2 = 5.3\n",
    "P3 = 5.78\n",
    "\n",
    "\n",
    "**Final Decision**: Using SAW, we found P1 to be the best Policy to be opted\n",
    "\n",
    "When we applied this method to find the best and the worst parcel, we found the results to be in conformance with our expectation. For example, we consider the actual area to be one of the most important factor. In the results also we found that the area of the best house is 5 times more than the worst house.Similarly, we expected that the more tax amount would decrease the desirability of the house and this is exactly what we observed in our results. The tax amount of the most desirable house was almost half of that of the least desirable house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rel_imp_matrix = pd.read_csv(\"./data/rel_imp_matrix.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fractions\n",
    "\n",
    "\n",
    "for col in rel_imp_matrix.columns.values:\n",
    "    temp_list = rel_imp_matrix[col].tolist()\n",
    "    rel_imp_matrix[col] = [float(fractions.Fraction(x))  for x in temp_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in rel_imp_matrix.columns.values:\n",
    "    rel_imp_matrix[col] /= rel_imp_matrix[col].sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rel_imp_matrix[\"row_sum\"] = rel_imp_matrix.sum(axis=1)\n",
    "\n",
    "rel_imp_matrix[\"score\"] = rel_imp_matrix[\"row_sum\"]/rel_imp_matrix.shape[0]\n",
    "\n",
    "rel_imp_matrix.to_csv(\"./data/final_score_matrix.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ahp_column_score = rel_imp_matrix[\"score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "sum_series = pd.Series(0, index=prop_data_ahp.index,dtype='float32')\n",
    "\n",
    "for col in prop_data_ahp.columns:\n",
    "    sum_series = sum_series+ prop_data_ahp[col] * ahp_column_score[col]\n",
    "prop_data_ahp[\"sum\"] = sum_series.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "prop_data_ahp.sort_values(by='sum', inplace=True,asce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_area</th>\n",
       "      <th>poolcnt</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>unitcnt</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>calculatedbathnbr</th>\n",
       "      <th>hashottuborspa</th>\n",
       "      <th>fireplacecnt</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>buildingqualitytypeid</th>\n",
       "      <th>garagecarcnt</th>\n",
       "      <th>age</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>342941</th>\n",
       "      <td>267.575106</td>\n",
       "      <td>-0.469740</td>\n",
       "      <td>0.246115</td>\n",
       "      <td>-0.256158</td>\n",
       "      <td>228.275624</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>353.180895</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-2.070526e+00</td>\n",
       "      <td>358.293102</td>\n",
       "      <td>111.634529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252741</th>\n",
       "      <td>242.589964</td>\n",
       "      <td>2.128838</td>\n",
       "      <td>0.246546</td>\n",
       "      <td>-0.408742</td>\n",
       "      <td>235.179911</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>333.351999</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-2.113163e+00</td>\n",
       "      <td>339.430872</td>\n",
       "      <td>106.440041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924829</th>\n",
       "      <td>-0.130731</td>\n",
       "      <td>-0.469740</td>\n",
       "      <td>0.200333</td>\n",
       "      <td>-0.167296</td>\n",
       "      <td>-0.059008</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>393.252942</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>4.141335e-13</td>\n",
       "      <td>396.090464</td>\n",
       "      <td>90.959091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462377</th>\n",
       "      <td>317.218010</td>\n",
       "      <td>2.128838</td>\n",
       "      <td>-0.950864</td>\n",
       "      <td>0.015457</td>\n",
       "      <td>468.446176</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>102.806498</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-1.942617e+00</td>\n",
       "      <td>106.327466</td>\n",
       "      <td>73.223297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938915</th>\n",
       "      <td>268.444343</td>\n",
       "      <td>2.128838</td>\n",
       "      <td>-0.173929</td>\n",
       "      <td>-0.629188</td>\n",
       "      <td>197.206333</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>186.599937</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-1.857344e+00</td>\n",
       "      <td>190.434473</td>\n",
       "      <td>70.807785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312470</th>\n",
       "      <td>-0.130731</td>\n",
       "      <td>-0.469740</td>\n",
       "      <td>0.184191</td>\n",
       "      <td>-0.154596</td>\n",
       "      <td>-0.059008</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>275.864483</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>4.141335e-13</td>\n",
       "      <td>287.105186</td>\n",
       "      <td>64.739670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104324</th>\n",
       "      <td>163.836910</td>\n",
       "      <td>-0.469740</td>\n",
       "      <td>0.184856</td>\n",
       "      <td>-0.170625</td>\n",
       "      <td>104.984786</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>179.653607</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-1.899980e+00</td>\n",
       "      <td>184.515721</td>\n",
       "      <td>57.376118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432636</th>\n",
       "      <td>263.035072</td>\n",
       "      <td>-0.469740</td>\n",
       "      <td>-0.097925</td>\n",
       "      <td>-0.621721</td>\n",
       "      <td>106.464276</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>155.507178</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-2.113163e+00</td>\n",
       "      <td>160.045797</td>\n",
       "      <td>56.830284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133400</th>\n",
       "      <td>233.175295</td>\n",
       "      <td>-0.469740</td>\n",
       "      <td>0.677687</td>\n",
       "      <td>-1.097497</td>\n",
       "      <td>167.123368</td>\n",
       "      <td>1.437383</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>100.819071</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-2.113163e+00</td>\n",
       "      <td>181.821091</td>\n",
       "      <td>55.717251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506261</th>\n",
       "      <td>1.194778</td>\n",
       "      <td>-0.469740</td>\n",
       "      <td>-1.064970</td>\n",
       "      <td>1.281310</td>\n",
       "      <td>-0.059008</td>\n",
       "      <td>1556.550294</td>\n",
       "      <td>1.500246</td>\n",
       "      <td>3.256529</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>1.748751</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>0.389016</td>\n",
       "      <td>-2.155799e+00</td>\n",
       "      <td>2.180908</td>\n",
       "      <td>51.425678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual_area   poolcnt  latitude  longitude     unitcnt  \\\n",
       "342941    267.575106 -0.469740  0.246115  -0.256158  228.275624   \n",
       "1252741   242.589964  2.128838  0.246546  -0.408742  235.179911   \n",
       "924829     -0.130731 -0.469740  0.200333  -0.167296   -0.059008   \n",
       "462377    317.218010  2.128838 -0.950864   0.015457  468.446176   \n",
       "1938915   268.444343  2.128838 -0.173929  -0.629188  197.206333   \n",
       "1312470    -0.130731 -0.469740  0.184191  -0.154596   -0.059008   \n",
       "104324    163.836910 -0.469740  0.184856  -0.170625  104.984786   \n",
       "432636    263.035072 -0.469740 -0.097925  -0.621721  106.464276   \n",
       "1133400   233.175295 -0.469740  0.677687  -1.097497  167.123368   \n",
       "1506261     1.194778 -0.469740 -1.064970   1.281310   -0.059008   \n",
       "\n",
       "         lotsizesquarefeet  bedroomcnt  calculatedbathnbr  hashottuborspa  \\\n",
       "342941           -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "1252741          -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "924829           -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "462377           -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "1938915          -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "1312470          -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "104324           -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "432636           -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "1133400           1.437383   -2.433835          -0.296309       -0.130599   \n",
       "1506261        1556.550294    1.500246           3.256529       -0.130599   \n",
       "\n",
       "         fireplacecnt  taxvaluedollarcnt  buildingqualitytypeid  garagecarcnt  \\\n",
       "342941      -0.315882         353.180895               0.325565     -2.484977   \n",
       "1252741     -0.315882         333.351999               0.325565     -2.484977   \n",
       "924829      -0.315882         393.252942               0.325565     -2.484977   \n",
       "462377      -0.315882         102.806498               0.325565     -2.484977   \n",
       "1938915     -0.315882         186.599937               0.325565     -2.484977   \n",
       "1312470     -0.315882         275.864483               0.325565     -2.484977   \n",
       "104324      -0.315882         179.653607               0.325565     -2.484977   \n",
       "432636      -0.315882         155.507178               0.325565     -2.484977   \n",
       "1133400     -0.315882         100.819071               0.325565     -2.484977   \n",
       "1506261     -0.315882           1.748751               0.325565      0.389016   \n",
       "\n",
       "                  age   taxamount         sum  \n",
       "342941  -2.070526e+00  358.293102  111.634529  \n",
       "1252741 -2.113163e+00  339.430872  106.440041  \n",
       "924829   4.141335e-13  396.090464   90.959091  \n",
       "462377  -1.942617e+00  106.327466   73.223297  \n",
       "1938915 -1.857344e+00  190.434473   70.807785  \n",
       "1312470  4.141335e-13  287.105186   64.739670  \n",
       "104324  -1.899980e+00  184.515721   57.376118  \n",
       "432636  -2.113163e+00  160.045797   56.830284  \n",
       "1133400 -2.113163e+00  181.821091   55.717251  \n",
       "1506261 -2.155799e+00    2.180908   51.425678  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_data_ahp.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_area</th>\n",
       "      <th>poolcnt</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>unitcnt</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>calculatedbathnbr</th>\n",
       "      <th>hashottuborspa</th>\n",
       "      <th>fireplacecnt</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>buildingqualitytypeid</th>\n",
       "      <th>garagecarcnt</th>\n",
       "      <th>age</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1850848</th>\n",
       "      <td>-0.571021</td>\n",
       "      <td>-0.46974</td>\n",
       "      <td>0.732088</td>\n",
       "      <td>-2.768679</td>\n",
       "      <td>-0.059008</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>-0.470565</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-2.113163</td>\n",
       "      <td>-0.485946</td>\n",
       "      <td>-0.923103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373342</th>\n",
       "      <td>-0.658666</td>\n",
       "      <td>-0.46974</td>\n",
       "      <td>0.667987</td>\n",
       "      <td>-2.743052</td>\n",
       "      <td>-0.059008</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>-0.447401</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-2.113163</td>\n",
       "      <td>-0.466640</td>\n",
       "      <td>-0.924429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508200</th>\n",
       "      <td>-0.684444</td>\n",
       "      <td>-0.46974</td>\n",
       "      <td>0.669178</td>\n",
       "      <td>-2.741512</td>\n",
       "      <td>-0.059008</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>-0.463418</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-2.070526</td>\n",
       "      <td>-0.490156</td>\n",
       "      <td>-0.925314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215255</th>\n",
       "      <td>-0.705067</td>\n",
       "      <td>-0.46974</td>\n",
       "      <td>-0.159019</td>\n",
       "      <td>-0.214175</td>\n",
       "      <td>-0.059008</td>\n",
       "      <td>-0.066811</td>\n",
       "      <td>-1.647019</td>\n",
       "      <td>-1.311405</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>-0.369170</td>\n",
       "      <td>-1.762694</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-1.857344</td>\n",
       "      <td>-0.369279</td>\n",
       "      <td>-0.926049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641843</th>\n",
       "      <td>-0.668977</td>\n",
       "      <td>-0.46974</td>\n",
       "      <td>0.668274</td>\n",
       "      <td>-2.741622</td>\n",
       "      <td>-0.059008</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>-0.470408</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-2.070526</td>\n",
       "      <td>-0.496827</td>\n",
       "      <td>-0.926168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553052</th>\n",
       "      <td>-0.663822</td>\n",
       "      <td>-0.46974</td>\n",
       "      <td>0.667029</td>\n",
       "      <td>-2.742575</td>\n",
       "      <td>-0.059008</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>-0.451344</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-2.113163</td>\n",
       "      <td>-0.478634</td>\n",
       "      <td>-0.926537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16136</th>\n",
       "      <td>-0.699911</td>\n",
       "      <td>-0.46974</td>\n",
       "      <td>0.785421</td>\n",
       "      <td>-2.817243</td>\n",
       "      <td>-0.059008</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>-0.467976</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-2.113163</td>\n",
       "      <td>-0.483379</td>\n",
       "      <td>-0.929569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506478</th>\n",
       "      <td>-0.830864</td>\n",
       "      <td>-0.46974</td>\n",
       "      <td>0.912452</td>\n",
       "      <td>-2.713674</td>\n",
       "      <td>-0.059008</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>-0.508389</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-2.113163</td>\n",
       "      <td>-0.525555</td>\n",
       "      <td>-0.930944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224123</th>\n",
       "      <td>-0.663822</td>\n",
       "      <td>-0.46974</td>\n",
       "      <td>0.668841</td>\n",
       "      <td>-2.742583</td>\n",
       "      <td>-0.059008</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>-0.482762</td>\n",
       "      <td>0.325565</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-2.113163</td>\n",
       "      <td>-0.508617</td>\n",
       "      <td>-0.933544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624243</th>\n",
       "      <td>-0.401916</td>\n",
       "      <td>-0.46974</td>\n",
       "      <td>-0.862954</td>\n",
       "      <td>-0.124989</td>\n",
       "      <td>-0.059008</td>\n",
       "      <td>-0.059489</td>\n",
       "      <td>-2.433835</td>\n",
       "      <td>-0.296309</td>\n",
       "      <td>-0.130599</td>\n",
       "      <td>-0.315882</td>\n",
       "      <td>-0.500707</td>\n",
       "      <td>-1.762694</td>\n",
       "      <td>-2.484977</td>\n",
       "      <td>-1.772071</td>\n",
       "      <td>-0.501905</td>\n",
       "      <td>-0.964943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual_area  poolcnt  latitude  longitude   unitcnt  \\\n",
       "1850848    -0.571021 -0.46974  0.732088  -2.768679 -0.059008   \n",
       "1373342    -0.658666 -0.46974  0.667987  -2.743052 -0.059008   \n",
       "508200     -0.684444 -0.46974  0.669178  -2.741512 -0.059008   \n",
       "215255     -0.705067 -0.46974 -0.159019  -0.214175 -0.059008   \n",
       "1641843    -0.668977 -0.46974  0.668274  -2.741622 -0.059008   \n",
       "553052     -0.663822 -0.46974  0.667029  -2.742575 -0.059008   \n",
       "16136      -0.699911 -0.46974  0.785421  -2.817243 -0.059008   \n",
       "2506478    -0.830864 -0.46974  0.912452  -2.713674 -0.059008   \n",
       "1224123    -0.663822 -0.46974  0.668841  -2.742583 -0.059008   \n",
       "2624243    -0.401916 -0.46974 -0.862954  -0.124989 -0.059008   \n",
       "\n",
       "         lotsizesquarefeet  bedroomcnt  calculatedbathnbr  hashottuborspa  \\\n",
       "1850848          -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "1373342          -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "508200           -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "215255           -0.066811   -1.647019          -1.311405       -0.130599   \n",
       "1641843          -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "553052           -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "16136            -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "2506478          -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "1224123          -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "2624243          -0.059489   -2.433835          -0.296309       -0.130599   \n",
       "\n",
       "         fireplacecnt  taxvaluedollarcnt  buildingqualitytypeid  garagecarcnt  \\\n",
       "1850848     -0.315882          -0.470565               0.325565     -2.484977   \n",
       "1373342     -0.315882          -0.447401               0.325565     -2.484977   \n",
       "508200      -0.315882          -0.463418               0.325565     -2.484977   \n",
       "215255      -0.315882          -0.369170              -1.762694     -2.484977   \n",
       "1641843     -0.315882          -0.470408               0.325565     -2.484977   \n",
       "553052      -0.315882          -0.451344               0.325565     -2.484977   \n",
       "16136       -0.315882          -0.467976               0.325565     -2.484977   \n",
       "2506478     -0.315882          -0.508389               0.325565     -2.484977   \n",
       "1224123     -0.315882          -0.482762               0.325565     -2.484977   \n",
       "2624243     -0.315882          -0.500707              -1.762694     -2.484977   \n",
       "\n",
       "              age  taxamount       sum  \n",
       "1850848 -2.113163  -0.485946 -0.923103  \n",
       "1373342 -2.113163  -0.466640 -0.924429  \n",
       "508200  -2.070526  -0.490156 -0.925314  \n",
       "215255  -1.857344  -0.369279 -0.926049  \n",
       "1641843 -2.070526  -0.496827 -0.926168  \n",
       "553052  -2.113163  -0.478634 -0.926537  \n",
       "16136   -2.113163  -0.483379 -0.929569  \n",
       "2506478 -2.113163  -0.525555 -0.930944  \n",
       "1224123 -2.113163  -0.508617 -0.933544  \n",
       "2624243 -1.772071  -0.501905 -0.964943  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_data_ahp.tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_area              1.048000e+03\n",
      "poolcnt                  0.000000e+00\n",
      "latitude                 3.379127e+07\n",
      "longitude               -1.182448e+08\n",
      "unitcnt                  1.000000e+00\n",
      "lotsizesquarefeet        7.000000e+03\n",
      "bedroomcnt               0.000000e+00\n",
      "calculatedbathnbr        2.000000e+00\n",
      "hashottuborspa           0.000000e+00\n",
      "fireplacecnt             0.000000e+00\n",
      "taxvaluedollarcnt        3.713500e+04\n",
      "buildingqualitytypeid    4.000000e+00\n",
      "garagecarcnt             0.000000e+00\n",
      "age                      1.100000e+01\n",
      "taxamount                5.712800e+02\n",
      "Name: 2624243, dtype: float64 \n",
      "\n",
      "\n",
      "actual_area              5.208250e+05\n",
      "poolcnt                  0.000000e+00\n",
      "latitude                 3.406122e+07\n",
      "longitude               -1.182901e+08\n",
      "unitcnt                  4.640000e+02\n",
      "lotsizesquarefeet        7.000000e+03\n",
      "bedroomcnt               0.000000e+00\n",
      "calculatedbathnbr        2.000000e+00\n",
      "hashottuborspa           0.000000e+00\n",
      "fireplacecnt             0.000000e+00\n",
      "taxvaluedollarcnt        2.870985e+08\n",
      "buildingqualitytypeid    7.000000e+00\n",
      "garagecarcnt             0.000000e+00\n",
      "age                      4.000000e+00\n",
      "taxamount                3.458861e+06\n",
      "Name: 342941, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print prop_data[colsList].iloc[2624243],\"\\n\\n\"\n",
    "print prop_data[colsList].iloc[342941]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise Distance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance_cols  = [\"actual_area\",\n",
    "                \"poolcnt\",\n",
    "                \"latitude\",\n",
    "                \"longitude\",\n",
    "                \"unitcnt\",\n",
    "                \"lotsizesquarefeet\",\n",
    "                \"bedroomcnt\",\n",
    "                \"calculatedbathnbr\",\n",
    "                \"hashottuborspa\",\n",
    "                \"fireplacecnt\",\n",
    "                \"taxvaluedollarcnt\",\n",
    "                \"buildingqualitytypeid\",\n",
    "                \"garagecarcnt\",\n",
    "                \"age\",\n",
    "                \"taxamount\",\n",
    "                \"airconditioningtypeid\",\n",
    "                 \"regionidcounty\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Features\n",
    "\n",
    "Before we dive into calculating the distance between two properties, we need to first find out what parameters we think are important in order to find out which properties are more similar to each other.\n",
    "\n",
    "After evaluation of the data available and considering real life logic, we have selected the following columns to find out the  \n",
    "distance between two properties:\n",
    "1. actual_area\n",
    "2. poolcnt\n",
    "3. latitude\n",
    "4. longitude\n",
    "5. unitcnt\n",
    "6. lotsizesquarefeet\n",
    "7. bedroomcnt\n",
    "8. calculatedbathnbr\n",
    "9. hashottuborspa\n",
    "10. fireplacecnt\n",
    "11. taxvaluedollarcnt\n",
    "12. buildingqualitytypeid\n",
    "13. garagecarcnt\n",
    "14. age\n",
    "15. taxamount\n",
    "16. airconditioningtypeid\n",
    "17. regionidcounty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_score = pd.read_csv('./data/column_scores_distance_metric.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative importance of features\n",
    "\n",
    "While we consider the above columns to calculate the distance between two values, it is only logical to assume that not all these columns are equally important while calculating the distance between the two properties. For example, whether the two properties belong to the same county is more important of a factor compared to a difference in the number of fireplaces available in the house.\n",
    "\n",
    "We use Analytic Hierarchy Process (AHP) to calculate the weight vector associated with different features. The process to do so is described in an earlier part of this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.drop_duplicates('parcelid',inplace=True)\n",
    "\n",
    "prop_data_dist = pd.merge(prop_data,train_data,on='parcelid')\n",
    "prop_data_dist = prop_data_dist[distance_cols]\n",
    "prop_data_dist.fillna(3101,inplace=True)\n",
    "prop_data_dist['regionidcounty'] = prop_data_dist['regionidcounty'].map({3101:1,1286:0,2061:-1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in prop_data_dist.columns:\n",
    "    prop_data_dist[col] = (prop_data_dist[col] - prop_data_dist[col].mean())/prop_data_dist[col].std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for i in distance_cols:\n",
    "    if i == 'regionidcounty':\n",
    "        prop_data_dist[i] = prop_data_dist[i]*col_score.ix['samecounty']['score']\n",
    "        continue\n",
    "    prop_data_dist[i] = prop_data_dist[i]*col_score.ix[i]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prop_data_dist.to_csv('prop_data_dist.csv',index=False)\n",
    "\n",
    "# prop_data_dist = pd.read_csv(\"prop_data_dist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pdist(prop_data_dist[:20000],metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a **weighted Euclidean distance** as a distance metric to calculate the distance between two properties. We calculate the distance over 20000 such properties to evaluate the performance of our distance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = squareform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.merge(prop_data,train_data,on='parcelid')\n",
    "\n",
    "temp = temp[distance_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini, minj = 0,1\n",
    "for i in range(result.shape[0]):\n",
    "    for j in range(i+1, result.shape[1]):\n",
    "        if result[i, j] < result[mini, minj] and result[i, j] != 0:\n",
    "            mini, minj  = i, j\n",
    "            \n",
    "\n",
    "print temp.iloc[mini]\n",
    "print \"\\n\\n\"\n",
    "print temp.iloc[minj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell, we try to print the values of the two houses which are different but have the smallest value of distance in the whole dataset. As it can be observed that most of the values in both the properties are the same, the only difference is that of a small amount in the tax values of the properties.\n",
    "\n",
    "This is a good indication that the distance metric is performing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxi, maxj = 0,1\n",
    "for i in range(result.shape[0]):\n",
    "    for j in range(i+1, result.shape[1]):\n",
    "        if result[i, j] > result[maxi, maxj]:\n",
    "            maxi, maxj  = i, j\n",
    "\n",
    "print temp.iloc[maxi]\n",
    "print \"\\n\\n\"\n",
    "print temp.iloc[maxj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find out the two properties that are the most different from each other. We can observe that there are stark differneces in most of the features of both the properties. For example, the first property is almost thrice as large as the second property (based on actual area), both the properties are physically far away from each other and also belong to different counties.\n",
    "\n",
    "\n",
    "This leads us to beleive that our distance function is doing a good job of finding out the similarity between two properties.\n",
    "This function can then be used when we implement clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters = 15,verbose=1, n_jobs=-1).fit(prop_data_dist)\n",
    "# kmeans.labels_\n",
    "\n",
    "# class_6 = []\n",
    "# for i in range(len(kmeans.labels_)):\n",
    "#     class_6.append(kmeans.labels_[i] == 7)\n",
    "# prop_data_dist[class_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## plotting the clusters here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging External Dataset\n",
    "\n",
    "### Datasets that can be merged: \n",
    "#### Schools available:\n",
    "This data can be useful for those people who have children who are school going age. If the house is near a school, then the residents have peace of mind knowing that the children are close by and can be accessed as and when needed. If the children are old enough to walk to school by themselves, then that saves a lot a transportation cost.\n",
    "Closer proximity to schools increases the desirability of the school and hence the resale value. Since, generally, there is more police presence near schools, this leads to better safety around them.\n",
    "Presence of a school nearby means that there would be a playground as well nearby. This factor attracts those people who might not have children but are interested in staying fit.\n",
    "The above-mentioned factors increase the desirability of the property and hence the price also increases.\n",
    "However, there are some disadvantages of living near schools as well. For example, increased traffic during school start and end times, noise from school events, parents parking their cars in the street causing traffic snarls which can be very annoying.\n",
    "**Final Verdict:** Living in an area near a school is like a double-edged sword. There are some factors which can jack up the price significantly but on the other side, there are some factors which could negatively affect the price. Final verdict varies from house to house, but we feel that the general trend is that having a school near your property is more advantageous from the standpoint of desirability.\n",
    "\n",
    "\n",
    "#### Recreational Facilities available:\n",
    "Availability of recreational facilities nearby is desired by people of every age. It can be helpful in maintaining both mental and physical fitness. It has been found that living in a non-green area can cause issues like loneliness and depression. In such areas, rates of aggression and violence has also been found higher.\n",
    "On the flip side, living near a recreational facility can have some problems like traffic snarls because of people trying to reach the facility especially on holidays and weekends, green areas attract wild animals like snakes which can be dangerous sometimes. \n",
    "**Final Verdict**: We think that availability of a recreational area near a property helps increase the property value because generally, people find such properties more desirable.\n",
    "Effects of such data-set on the Zestimate: The presence of these facilities near a property increases its value. In our case, if Zillow had not factoring them in, then this could cause an increase in the value of the logerror. Also, if a new school or a recreational facility opens up after the assessment by Zillow, then that could also lead to an increase in the logerror of that property.\n",
    "\n",
    "\n",
    "#### Integration of data: \n",
    "We plan to integrate this data into our model by measuring the distance between the co-ordinates of the properties and the recreational facility or school zone. The school zone is calculated by taking its co-ordinate upto 1 decimal place, this creates a circular zone of around 11 miles around the school, which then can be compared with the propertys co-ordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec = pd.read_csv('./data/RecAreas_CSV.csv')\n",
    "rec = rec[np.isfinite(rec['RECAREALATITUDE'])]\n",
    "rec = rec[np.isfinite(rec['RECAREALONGITUDE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec_zones = {}\n",
    "s = set()\n",
    "decimal_places = 2\n",
    "# print(len(rec))\n",
    "for row in rec.iterrows():\n",
    "\n",
    "    dot_index = str(row[1][7]).index(\".\")\n",
    "    long_str = str(row[1][7])[:dot_index+decimal_places]\n",
    "    dot_index = str(row[1][6]).index(\".\")\n",
    "    lat_str = str(row[1][6])[:dot_index+decimal_places]\n",
    "    if (lat_str,long_str) in rec_zones:\n",
    "       rec_zones[(lat_str,long_str)] += 1\n",
    "    else:\n",
    "       rec_zones[(lat_str,long_str)] = 1\n",
    "#    s.add(lat_str+\"\"+long_str)\n",
    "#     print((row[1][7]),\" \",long_str)\n",
    "#     print((row[1][6]),\" \",lat_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pub_schools = pd.read_csv('./data/pubschls.csv')\n",
    "\n",
    "pub_schools = pub_schools[(pub_schools['County'] == 'Los Angeles') | (pub_schools['County'] == 'Orange') | (pub_schools['County'] == 'Ventura')]\n",
    "pub_schools = pub_schools[pub_schools['StatusType'] != 'Closed']\n",
    "pub_schools = pub_schools[np.isfinite(pub_schools['Latitude'])]\n",
    "pub_schools = pub_schools[np.isfinite(pub_schools['Longitude'])]\n",
    "\n",
    "\n",
    "\n",
    "pub_schools = pub_schools[pub_schools['SOC'].isin([60,62,66,65])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zones = {}\n",
    "decimal_places = 2\n",
    "for row in pub_schools.iterrows():\n",
    "   dot_index = str(row[1]['Longitude']).index(\".\")\n",
    "   long_str = str(row[1]['Longitude'])[:dot_index+decimal_places]\n",
    "   dot_index = str(row[1]['Latitude']).index(\".\")\n",
    "   lat_str = str(row[1]['Latitude'])[:dot_index+decimal_places]\n",
    "   if (lat_str,long_str) in zones:\n",
    "       zones[(lat_str,long_str)] += 1\n",
    "   else:\n",
    "       zones[(lat_str,long_str)] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.merge(prop_data,train_data,on='parcelid')\n",
    "\n",
    "data = data[distance_cols + ['parcelid','logerror']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_data = prop_data[np.isfinite(prop_data['latitude'])]\n",
    "prop_data = prop_data[np.isfinite(prop_data['longitude'])]\n",
    "decimal_places=2\n",
    "\n",
    "num_schools = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[np.isfinite(data['latitude'])]\n",
    "data = data[np.isfinite(data['longitude'])]\n",
    "decimal_places=2\n",
    "\n",
    "num_schools = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_schools = []\n",
    "num_rec = []\n",
    "for row in prop_data.iterrows():\n",
    "    long = row[1]['longitude']/1000000\n",
    "    lat =  row[1]['latitude']/1000000\n",
    "    #     print(str(row[1]['longitude'])[:5])\n",
    "    dot_index = str(long).index(\".\")\n",
    "    long_str = str(long)[:dot_index+decimal_places]\n",
    "    dot_index = str(lat).index(\".\")\n",
    "    lat_str = str(lat)[:dot_index+decimal_places]\n",
    "    if (lat_str,long_str) in zones:\n",
    "        num_schools.append(zones[(lat_str,long_str)])\n",
    "    else:\n",
    "        num_schools.append(0)\n",
    "    if (lat_str,long_str) in rec_zones:\n",
    "        num_rec.append(rec_zones[(lat_str,long_str)])\n",
    "    else:\n",
    "        num_rec.append(0)\n",
    "\n",
    "\n",
    "prop_data['num_schools'] = num_schools\n",
    "prop_data['num_rec']  = num_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_data.to_csv('./data/unnormalized_prop_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/jay/.local/lib/python2.7/site-packages/numpy/lib/arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "prop_data = pd.read_csv(\"./data/unnormalized_prop_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 41, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\nImportError: libnvidia-fatbinaryloader.so.375.66: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3cd412c9a39e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Globally-importable utils.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown backend: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BACKEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 41, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\nImportError: libnvidia-fatbinaryloader.so.375.66: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "print( \"\\n\\nProcessing data for Neural Network ...\")\n",
    "print('\\nLoading train, prop and sample data...')\n",
    "\n",
    "train_data = pd.read_csv(\"./data/train_2017.csv\", parse_dates=[\"transactiondate\"])\n",
    "prop = prop_data#pd.read_csv(\"./train_data_clean_2.csv\")\n",
    "sample = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "print('Fitting Label Encoder on properties...')\n",
    "for c in prop.columns:\n",
    "    prop[c]=prop[c].fillna(-1)\n",
    "    if prop[c].dtype == 'object':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(prop[c].values))\n",
    "        prop[c] = lbl.transform(list(prop[c].values))\n",
    "\n",
    "print('Creating training set...')\n",
    "df_train = train_data.merge(prop, how='left', on='parcelid')\n",
    "\n",
    "df_train[\"transactiondate\"] = pd.to_datetime(df_train[\"transactiondate\"])\n",
    "df_train[\"transactiondate_year\"] = df_train[\"transactiondate\"].dt.year\n",
    "df_train[\"transactiondate_month\"] = df_train[\"transactiondate\"].dt.month\n",
    "df_train['transactiondate_quarter'] = df_train['transactiondate'].dt.quarter\n",
    "df_train[\"transactiondate\"] = df_train[\"transactiondate\"].dt.day\n",
    "\n",
    "# print('Creating x_train and y_train from df_train...' )\n",
    "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate'], axis=1)\n",
    "y_train = df_train[\"logerror\"]\n",
    "\n",
    "train_columns = x_train.columns\n",
    "print train_columns\n",
    "\n",
    "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n",
    "    x_train[c] = (x_train[c] == True)\n",
    "\n",
    "print('Creating df_test...')\n",
    "sample['parcelid'] = sample['ParcelId']\n",
    "test_months = [k for k in sample.columns.values if k not in [\"parcelid\"]]\n",
    "\n",
    "print(\"Merging Sample with property data...\")\n",
    "df_test = sample.merge(prop, on='parcelid', how='left')\n",
    "\n",
    "# ## Preprocessing\n",
    "print(\"\\nPreprocessing neural network data...\")\n",
    "\n",
    "df_test[\"transactiondate\"] = pd.to_datetime('2016-11-15')  # placeholder value for preliminary version\n",
    "df_test[\"transactiondate_year\"] = df_test[\"transactiondate\"].dt.year\n",
    "df_test[\"transactiondate_month\"] = df_test[\"transactiondate\"].dt.month\n",
    "df_test['transactiondate_quarter'] = df_test['transactiondate'].dt.quarter\n",
    "df_test[\"transactiondate\"] = df_test[\"transactiondate\"].dt.day     \n",
    "x_test = df_test[train_columns]\n",
    "\n",
    "print('Shape of x_test:', x_test.shape)\n",
    "print(\"Preparing x_test...\")\n",
    "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n",
    "    x_test[c] = (x_test[c] == True)\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "len_x=int(x_train.shape[1])\n",
    "print(\"len_x is:\",len_x)\n",
    "\n",
    "\n",
    "# Neural Network\n",
    "print(\"\\nSetting up neural network model...\")\n",
    "nn = Sequential()\n",
    "nn.add(Dense(units = 400 , kernel_initializer = 'normal', input_dim = len_x))\n",
    "nn.add(PReLU())\n",
    "nn.add(Dropout(.4))\n",
    "nn.add(Dense(units = 160 , kernel_initializer = 'normal'))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(.63))\n",
    "nn.add(Dense(units = 64 , kernel_initializer = 'normal'))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(.45))\n",
    "nn.add(Dense(units = 28, kernel_initializer = 'normal'))\n",
    "nn.add(PReLU())\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(.5))\n",
    "nn.add(Dense(1, kernel_initializer='normal'))\n",
    "nn.compile(loss='mae', optimizer=Adam(lr=4e-3, decay=1e-4))\n",
    "\n",
    "print(\"\\nFitting neural network model...\")\n",
    "nn.fit(np.array(x_train), np.array(y_train), batch_size = 32, epochs = 70, verbose=2)\n",
    "\n",
    "test_dates = ['2016-10-01','2016-11-01','2016-12-01','2017-10-01','2017-11-01','2017-12-01']\n",
    "test_columns = ['201610','201611','201612','201710','201711','201712']\n",
    "nn_pred = {}\n",
    "\n",
    "for i in range(len(test_columns)):\n",
    "\n",
    "    df_test[\"transactiondate\"] = pd.to_datetime(test_dates[i])\n",
    "    df_test[\"transactiondate_year\"] = df_test[\"transactiondate\"].dt.year\n",
    "    df_test[\"transactiondate_month\"] = df_test[\"transactiondate\"].dt.month\n",
    "    df_test['transactiondate_quarter'] = df_test['transactiondate'].dt.quarter\n",
    "    df_test[\"transactiondate\"] = df_test[\"transactiondate\"].dt.day     \n",
    "    x_test = df_test[train_columns]\n",
    "\n",
    "    print('Shape of x_test:', x_test.shape)\n",
    "    print(\"Preparing x_test...\")\n",
    "    for c in x_test.dtypes[x_test.dtypes == object].index.values:\n",
    "        x_test[c] = (x_test[c] == True)\n",
    "\n",
    "    x_test = sc.transform(x_test)\n",
    "    print(\"\\nPredicting with neural network model...\")\n",
    "    #print(\"x_test.shape:\",x_test.shape)\n",
    "    y_pred_ann = nn.predict(x_test)\n",
    "\n",
    "    print( \"\\nPreparing results for write...\" )\n",
    "    nn_pred[test_columns[i]] = y_pred_ann.flatten()\n",
    "    \n",
    "    print( \"Type of nn_pred is \", type(nn_pred[test_columns[i]]) )\n",
    "    print( \"Shape of nn_pred is \", nn_pred[test_columns[i]].shape )\n",
    "\n",
    "    print( \"\\nNeural Network predictions:\" )\n",
    "    print( pd.DataFrame(nn_pred[test_columns[i]]).head() )\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "for date in test_columns:\n",
    "    sample[date] = nn_pred[date]\n",
    "\n",
    "sample[\"ParcelId\"] = sample[\"parcelid\"]\n",
    "sample.drop([\"parcelid\"], axis=1, inplace=True)\n",
    "\n",
    "print( \"\\nWriting results to disk ...\" )\n",
    "sample.to_csv('NN_sub{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False)\n",
    "\n",
    "print( \"\\nFinished ...\")\n",
    "\n",
    "# Cleanup\n",
    "del train_data\n",
    "del prop\n",
    "del sample\n",
    "del x_train\n",
    "del x_test\n",
    "del df_train\n",
    "del df_test\n",
    "# del y_pred_ann\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Description of MLP\n",
    "\n",
    "<br><br>\n",
    "- This model is based on the way a Human brain works.<br>\n",
    "- It is basically an arrangement of small units called Neurons.<br>\n",
    "- These neurons are connected with other neurons in the next layer.<br> \n",
    "- The neurons are activated on the basis of the input to the activation function.<br>\n",
    "\n",
    "<img src=\"http://scikit-learn.org/stable/_images/multilayerperceptron_network.png\" width=\"400\" height=\"400\" alt=\"Alt text that describes the graphic\" title=\"Title text\" />\n",
    "\n",
    "Each Layer has assigned weights to each incoming connection to the neurons in the layer and also each layer has a bias term. <br><br>\n",
    "\n",
    "The Image represents a basic neural network.\n",
    "\n",
    "The leftmost layer, known as the input layer, consists of a set of neurons \\{x_i | x_1, x_2, ..., x_m\\} representing the input features. Each neuron in the hidden layer transforms the values from the previous layer with a weighted linear summation w_1\\*x_1 + w_2\\*x_2 + ... + w_m*x_m, followed by a non-linear activation function like the hyperbolic tan function. The output layer receives the values from the last hidden layer and transforms them into output values.\n",
    "\n",
    "\n",
    "There were a few surprises when using this model.<br>\n",
    "One of them was that the model while training had random jumps in the Loss,\n",
    "which was counter-intuitive, because as the training is done, the loss should decrease. Later, on reading about it. I realised that it because this SKlearn implementation uses Stocastic Gradient Descent by default, which make random jumps in gradients to converge faster and to avoid a local minima.\n",
    "\n",
    "### Hyperparameters to tune the Model\n",
    "1. Number of hidden layer and the size of each layer - a single hidden layer is enough to model a linear data.\n",
    "    However, as the data becomes more complex, it can be modelled by using more number of hidden layer.\n",
    "2. Solver and optimizer - There are multiple solvers used for weight optimization of the MLP, these include\n",
    "    - lbfgs is an optimizer in the family of quasi-Newton methods.\n",
    "    - sgd refers to stochastic gradient descent.\n",
    "    - adam refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "3. Learning rate - A high learning rate means that the model is sensitive to outliers and variance. And a small learning rate means that the model is biased towards the data it observed previously. It is important to strike a balance here.\n",
    "4. Activation Function - {identity, logistic, tanh, relu}\n",
    "    Activation function for the hidden layer.\n",
    "    - identity, no-op activation, useful to implement linear bottleneck, returns f(x) = x\n",
    "    - logistic, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n",
    "    - tanh, the hyperbolic tan function, returns f(x) = tanh(x).\n",
    "    - relu, the rectified linear unit function, returns f(x) = max(0, x)\n",
    "5. alpha - L2 penalty (regularization term) parameter.\n",
    "\n",
    "These are the major parameters to tune while training a MLP neural network.\n",
    "\n",
    "### Features Selection\n",
    "\n",
    "We will be using the following features:\n",
    "- \"transactiondate_year\"\n",
    "- \"transactiondate_month\"\n",
    "- \"transactiondate_quarter\"\n",
    "- \"actual_area\",\n",
    "- \"poolcnt\",\n",
    "- \"latitude\",\n",
    "- \"longitude\",\n",
    "- \"unitcnt\",\n",
    "- \"lotsizesquarefeet\",\n",
    "- \"bedroomcnt\",\n",
    "- \"calculatedbathnbr\",\n",
    "- \"hashottuborspa\",\n",
    "- \"fireplacecnt\",\n",
    "- \"taxvaluedollarcnt\",\n",
    "- \"buildingqualitytypeid\",\n",
    "- \"garagecarcnt\",\n",
    "- \"age\",\n",
    "- \"taxamount\",\n",
    "- \"airconditioningtypeid\",\n",
    "- \"regionidcounty\"\n",
    "\n",
    "### Evalution of the Model\n",
    "\n",
    "Here we are evaluating the model by splitting the data into training and validation sets. We then fit the models on the training sets and then predict the values of the validation set. These prediction are checked for finding the MAE. \n",
    "\n",
    "NN on Validation Data:\n",
    "MAE - 0.0690\n",
    "\n",
    "NN on Testing Data:\n",
    "MAE - 0.0648571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "# y_predict = (regr.predict(X_test))\n",
    "y_predict = y_pred_ann\n",
    "print(type(y_test))\n",
    "mse = pd.Series()\n",
    "print(\"Mean Square Error\",mean_squared_error(y_test, y_predict))\n",
    "for i in range(0,100):\n",
    "    y_permutation = shuffle(y_test)\n",
    "    mse = mse.append(pd.Series([mean_squared_error(y_permutation, y_predict)]))\n",
    "print(len(mse))\n",
    "sns.distplot(mse);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
